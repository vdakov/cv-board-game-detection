{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from board_detection import homography_dataset\n",
    "from board_detection.homomography_network import HomographyNet\n",
    "from board_detection.homomography_training import show_perspective_corrected_board\n",
    "from board_detection.homomography_training import load_dataset\n",
    "from board_detection.homomography_training import train_model\n",
    "from board_detection.homomography_training import calculate_test_loss\n",
    "from board_detection.homography_loss import PhotometricLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_transform_pipeline = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "label_transform_pipeline = transforms.Compose([\n",
    "    homography_dataset.HomographyOutputTransform((512, 512), (128, 128)),\n",
    "    transforms.Lambda(lambda x: torch.tensor(x, dtype=torch.float32)), \n",
    "    transforms.Lambda(lambda x: torch.flatten(x))\n",
    "])\n",
    "\n",
    "json_path = \"pre_processing/data/output/perspective_distorted_boards/bbox_coordinates.json\"\n",
    "img_dir = \"pre_processing/data/output/perspective_distorted_boards\"\n",
    "\n",
    "dataset = load_dataset(json_path, img_dir, input_transform_pipeline, label_transform_pipeline)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 52\n",
    "model = HomographyNet(9) #9 cuz the matrix is flat 3 x 3\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = PhotometricLoss()\n",
    "device = \"cpu\"\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "save_path = \"runs/models/homomography_hybrid_model.pth\"\n",
    "# save_path = None\n",
    "resume_path = \"runs/models/homomography_model.pth\"\n",
    "# resume_path = None\n",
    "\n",
    "\n",
    "train_losses = train_model(model, train_loader, criterion, optimizer, num_epochs, device, save_path, resume_path)\n",
    "test_loss = calculate_test_loss(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import show_loss \n",
    "show_loss.show_train_test_loss(train_losses[:52], test_loss, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset.__getitem__(np.random.randint(0, dataset.__len__()))\n",
    "\n",
    "matrix = model(image.unsqueeze(0))\n",
    "\n",
    "# label, matrix = label.detach().numpy().reshape(3, 3), \n",
    "print(label.detach().numpy().reshape(3, 3))\n",
    "print(matrix.detach().numpy().reshape(3, 3))\n",
    "show_perspective_corrected_board(model, image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from board_detection.yolo_extraction import board_detection_step\n",
    "\n",
    "\n",
    "data_dir = \"data/sample/perspective_distorted_boards_sample/images\"\n",
    "model_path = \"board_detection/data/input/runs/train10/weights/best.pt\"  # Replace with your trained model\n",
    "class_id_to_find = 0  # Change this to the class ID of the object you want to search for\n",
    "\n",
    "model = YOLO(model_path)\n",
    "# Run detection & plot results\n",
    "board_detection_step(\"data/full/perspective_distorted_boards/train/images/canvas_image_0.png\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
